{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f97446b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import psycopg2\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from typing import List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"white\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ed1bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "MIMIC_FOLDER = \"\"\n",
    "conn = psycopg2.connect(\"user=username password=password dbname=mimiciv\")\n",
    "\n",
    "def build_query(\n",
    "    table_name: str,\n",
    "    column_names: Optional[List[str]] = None,\n",
    "    conditions: Optional[List[str]] = None,\n",
    "    limit: Optional[int] = None\n",
    "):\n",
    "    if column_names is not None:\n",
    "        col_str = \",\".join(column_names)\n",
    "    else:\n",
    "        col_str = \"*\"\n",
    "    limit_str = \"\"\n",
    "    if limit is not None:\n",
    "        limit_str += f\" LIMIT {limit}\"\n",
    "    condition_str = \"\"\n",
    "    if conditions is not None:\n",
    "        condition_str += (\" WHERE \" + \" AND \".join(conditions))\n",
    "    return f\"SELECT {col_str} from {table_name}\" + condition_str + limit_str\n",
    "\n",
    "\n",
    "def run_query(query: str, preview: Optional[bool] = True, save_to: str = None, **kwargs):\n",
    "    print(\"EXECUTING QUERY:\", query)\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    if preview:\n",
    "        display(df)\n",
    "    if save_to is not None:\n",
    "        print(f\"Saved to {save_to}\")\n",
    "        df.to_csv(save_to, **kwargs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534ac33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "patients_df = pd.read_csv(f\"{MIMIC_FOLDER}/mimiciv/2.2/hosp/patients.csv.gz\")\n",
    "hadms = pd.read_csv(f\"{MIMIC_FOLDER}/mimiciv/2.2/hosp/admissions.csv.gz\", low_memory=False)\n",
    "icustay_df = pd.read_csv(f\"{MIMIC_FOLDER}/mimiciv/2.2/icu/icustays.csv.gz\")\n",
    "\n",
    "print(icustay_df.columns)\n",
    "\n",
    "# Take sample of 10000 subject ids\n",
    "subject_ids = patients_df['subject_id'].drop_duplicates()\n",
    "\n",
    "filtered_hadms = hadms[hadms['subject_id'].isin(subject_ids)]\n",
    "filtered_hadms = filtered_hadms.merge(patients_df[['subject_id', 'gender']], on='subject_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c1270",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Build cohort from MIMIC only: start with admissions (no external cohort load)\n",
    "valid_admissions = filtered_hadms[\n",
    "    filtered_hadms['admission_type'].fillna('').str.upper().isin(('EW EMER.', 'DIRECT EMER.', 'URGENT'))\n",
    "].copy()\n",
    "# Placeholder label; overwritten below by task-specific logic (los, lactate_threshold, in_icu_mortality)\n",
    "valid_admissions['boolean_value'] = False\n",
    "\n",
    "# ICU timing/LOS comes from the derived table\n",
    "icu_admissions = run_query(\n",
    "    build_query(\n",
    "        \"mimiciv_derived.icustay_detail\",\n",
    "        column_names=[\"hadm_id\", \"stay_id\", \"icu_intime\", \"icu_outtime\"]\n",
    "    ),\n",
    "    preview=False\n",
    ")\n",
    "icu_admissions['icu_intime'] = pd.to_datetime(icu_admissions['icu_intime'])\n",
    "icu_admissions['icu_outtime'] = pd.to_datetime(icu_admissions['icu_outtime'])\n",
    "\n",
    "# Keep the first ICU stay for each hospital admission so we retain stay_id for ICU vitals joins\n",
    "first_icu_by_hadm = (\n",
    "    icu_admissions\n",
    "    .dropna(subset=['hadm_id', 'stay_id', 'icu_intime'])\n",
    "    .sort_values(['hadm_id', 'icu_intime'])\n",
    "    .drop_duplicates('hadm_id', keep='first')\n",
    "    [['hadm_id', 'stay_id', 'icu_intime', 'icu_outtime']]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ICU type (careunit) comes from the raw ICU table (already loaded as icustay_df)\n",
    "careunit_by_stay = (\n",
    "    icustay_df[['stay_id', 'first_careunit', 'last_careunit']]\n",
    "    .drop_duplicates('stay_id')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "first_icu_by_hadm = first_icu_by_hadm.merge(careunit_by_stay, on='stay_id', how='left')\n",
    "\n",
    "first_icu_by_hadm['icu_los_hours'] = (\n",
    "    first_icu_by_hadm['icu_outtime'] - first_icu_by_hadm['icu_intime']\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "# Parameter: hours after ICU intime at which we define prediction_time\n",
    "PREDICTION_HOURS_AFTER_ICU = 48  # customize this (e.g., 24, 48, 72, ...)\n",
    "OBSERVATION_TIME = 48  # hours to look back for observations\n",
    "# Label definition for task 'mortality': 'in_icu_mortality' = death during ICU stay (after prediction_time); 'hospital' = any in-hospital death\n",
    "MORTALITY_LABEL_DEFINITION = 'in_icu_mortality'  # or 'hospital'\n",
    "\n",
    "# Merge ICU timing and set prediction time to PREDICTION_HOURS_AFTER_ICU after ICU admission\n",
    "valid_admissions = valid_admissions.merge(first_icu_by_hadm, on='hadm_id', how='inner')\n",
    "valid_admissions['icu_intime'] = pd.to_datetime(valid_admissions['icu_intime'])\n",
    "\n",
    "# New prediction_time definition: PREDICTION_HOURS_AFTER_ICU hours after ICU intime\n",
    "valid_admissions['prediction_time'] = valid_admissions['icu_intime'] + pd.Timedelta(hours=PREDICTION_HOURS_AFTER_ICU)\n",
    "\n",
    "# Require at least PREDICTION_HOURS_AFTER_ICU of ICU stay and prediction within the hospital stay window\n",
    "valid_admissions = valid_admissions[\n",
    "    (valid_admissions['icu_los_hours'] >= PREDICTION_HOURS_AFTER_ICU) &\n",
    "    (valid_admissions['prediction_time'] >= valid_admissions['admittime']) &\n",
    "    (valid_admissions['prediction_time'] <= valid_admissions['dischtime'])\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# If task is long ICU LOS (\"los\"), define label: 1 if ICU stay > 7 days\n",
    "if task == 'los':\n",
    "    valid_admissions['boolean_value'] = (valid_admissions['icu_los_hours'] > 7 * 24).astype(int)\n",
    "\n",
    "# If task is lactate threshold, check if lactate > 2 in next 24h after prediction_time\n",
    "if task == 'lactate_threshold':\n",
    "    # Query lactate values from bg table\n",
    "    bg_df = run_query(\n",
    "        build_query(\"mimiciv_derived.bg\", column_names=[\"hadm_id\", \"charttime\", \"lactate\"]),\n",
    "        preview=False\n",
    "    )\n",
    "    bg_df['charttime'] = pd.to_datetime(bg_df['charttime'])\n",
    "    bg_df = bg_df.dropna(subset=['lactate', 'charttime'])\n",
    "    \n",
    "    # Merge with valid_admissions to get prediction_time\n",
    "    bg_with_pred = bg_df.merge(\n",
    "        valid_admissions[['hadm_id', 'prediction_time']],\n",
    "        on='hadm_id',\n",
    "        how='inner'\n",
    "    )\n",
    "    bg_with_pred['prediction_time'] = pd.to_datetime(bg_with_pred['prediction_time'])\n",
    "    \n",
    "    # Filter to measurements in [prediction_time, prediction_time + 24h]\n",
    "    mask = (\n",
    "        (bg_with_pred['charttime'] >= bg_with_pred['prediction_time']) &\n",
    "        (bg_with_pred['charttime'] <= bg_with_pred['prediction_time'] + pd.Timedelta(hours=24))\n",
    "    )\n",
    "    lactate_future = bg_with_pred.loc[mask]\n",
    "    \n",
    "    # Keep only patients with at least one lactate measurement in the 24h window\n",
    "    hadm_ids_with_lactate = set(lactate_future['hadm_id'].unique())\n",
    "    valid_admissions = valid_admissions[valid_admissions['hadm_id'].isin(hadm_ids_with_lactate)].reset_index(drop=True)\n",
    "    \n",
    "    # For each hadm_id, label = 1 if any lactate > 2 in window, else 0\n",
    "    lactate_label = (\n",
    "        lactate_future\n",
    "        .groupby('hadm_id')['lactate']\n",
    "        .max()\n",
    "        .gt(2)\n",
    "        .astype(int)\n",
    "        .rename('lactate_label')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Merge label back and overwrite boolean_value\n",
    "    valid_admissions = valid_admissions.merge(lactate_label, on='hadm_id', how='left')\n",
    "    valid_admissions['boolean_value'] = valid_admissions['lactate_label'].fillna(0).astype(int)\n",
    "    valid_admissions = valid_admissions.drop(columns=['lactate_label'])\n",
    "\n",
    "# ICU type for the selected ICU stay\n",
    "valid_admissions['icu_type'] = valid_admissions['first_careunit'].fillna(valid_admissions['last_careunit'])\n",
    "\n",
    "# Drop ICU types with < 500 samples or missing ICU type\n",
    "icu_counts = valid_admissions['icu_type'].value_counts()\n",
    "valid_admissions = valid_admissions[\n",
    "    valid_admissions['icu_type'].notna() &\n",
    "    valid_admissions['icu_type'].isin(icu_counts[icu_counts >= 500].index)\n",
    "]\n",
    "\n",
    "# Operation type: first coded procedure in the admission\n",
    "operation_df = run_query(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT ON (p.hadm_id)\n",
    "        p.hadm_id,\n",
    "        dp.long_title AS operation_type\n",
    "    FROM mimiciv_hosp.procedures_icd p\n",
    "    LEFT JOIN mimiciv_hosp.d_icd_procedures dp\n",
    "      ON p.icd_code = dp.icd_code\n",
    "     AND p.icd_version = dp.icd_version\n",
    "    WHERE p.hadm_id IS NOT NULL\n",
    "    ORDER BY p.hadm_id, p.seq_num NULLS LAST\n",
    "    \"\"\",\n",
    "    preview=False\n",
    ")\n",
    "\n",
    "valid_admissions = valid_admissions.merge(operation_df, on='hadm_id', how='left')\n",
    "\n",
    "# Ventilation status at prediction_time (from mimiciv_derived.ventilation; run concepts if missing)\n",
    "vent_df = run_query(\n",
    "    build_query(\"mimiciv_derived.ventilation\", column_names=[\"stay_id\", \"starttime\", \"endtime\", \"ventilation_status\"]),\n",
    "    preview=False\n",
    ")\n",
    "vent_df['starttime'] = pd.to_datetime(vent_df['starttime'])\n",
    "vent_df['endtime'] = pd.to_datetime(vent_df['endtime'])\n",
    "adm_vent = valid_admissions[['hadm_id', 'stay_id', 'prediction_time']].merge(vent_df, on='stay_id', how='left')\n",
    "adm_vent['prediction_time'] = pd.to_datetime(adm_vent['prediction_time'])\n",
    "mask = (adm_vent['starttime'] <= adm_vent['prediction_time']) & (adm_vent['prediction_time'] <= adm_vent['endtime'])\n",
    "vent_at_pred = adm_vent.loc[mask].drop_duplicates('hadm_id', keep='first')[['hadm_id', 'ventilation_status']]\n",
    "valid_admissions = valid_admissions.merge(vent_at_pred, on='hadm_id', how='left')\n",
    "# Impute missing ventilation_status as \"None\" (no missingness indicator will be created)\n",
    "valid_admissions['ventilation_status'] = valid_admissions['ventilation_status'].fillna('None')\n",
    "\n",
    "# Override label based on LABEL_DEFINITION\n",
    "if task == 'mortality' and MORTALITY_LABEL_DEFINITION == 'in_icu_mortality':\n",
    "    valid_admissions['deathtime'] = pd.to_datetime(valid_admissions['deathtime'])\n",
    "    valid_admissions['icu_outtime'] = pd.to_datetime(valid_admissions['icu_outtime'])\n",
    "    # Exclude patients who died before prediction_time (temporal leakage prevention)\n",
    "    valid_admissions = valid_admissions[\n",
    "        (valid_admissions['deathtime'].isna()) | \n",
    "        (valid_admissions['deathtime'] >= valid_admissions['prediction_time'])\n",
    "    ].reset_index(drop=True)\n",
    "    # True if death occurred during the first ICU stay AFTER prediction_time (between prediction_time and icu_outtime)\n",
    "    valid_admissions['boolean_value'] = (\n",
    "        valid_admissions['deathtime'].notna()\n",
    "        & (valid_admissions['deathtime'] >= valid_admissions['prediction_time'])\n",
    "        & (valid_admissions['deathtime'] <= valid_admissions['icu_outtime'])\n",
    "    )\n",
    "elif task == 'mortality' and MORTALITY_LABEL_DEFINITION == 'hospital':\n",
    "    valid_admissions['deathtime'] = pd.to_datetime(valid_admissions['deathtime'])\n",
    "    valid_admissions = valid_admissions[\n",
    "        (valid_admissions['deathtime'].isna()) |\n",
    "        (valid_admissions['deathtime'] >= valid_admissions['prediction_time'])\n",
    "    ].reset_index(drop=True)\n",
    "    valid_admissions['boolean_value'] = valid_admissions['deathtime'].notna()\n",
    "\n",
    "print(valid_admissions.columns)\n",
    "\n",
    "# Keep only the required columns, including ICU, operation, and ventilation.\n",
    "valid_admissions = valid_admissions[[\n",
    "    'subject_id', 'hadm_id', 'stay_id', 'boolean_value', 'prediction_time',\n",
    "    'admittime', 'dischtime', 'race', 'insurance', 'gender',\n",
    "    'icu_type', 'operation_type', 'ventilation_status'\n",
    "]].reset_index(drop=True)\n",
    "valid_admissions = valid_admissions.drop_duplicates('subject_id', keep='first')\n",
    "print(valid_admissions['boolean_value'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27df420",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import test_proportions_2indep \n",
    "\n",
    "all_hadms = set(valid_admissions.hadm_id.dropna().tolist())\n",
    "all_stays = set(valid_admissions['stay_id'].dropna().tolist()) if 'stay_id' in valid_admissions.columns else set()\n",
    "\n",
    "def extract_features(lab_df, admissions, columns_to_mean, time=OBSERVATION_TIME, join_col='hadm_id', combined_ids=None):\n",
    "    if combined_ids is None:\n",
    "        combined_ids = set(admissions[join_col].dropna().tolist())\n",
    "\n",
    "    df = lab_df.merge(admissions[[join_col, 'prediction_time']], on=join_col, how='inner')\n",
    "\n",
    "    # Some tables are event-level (with charttime), while others are already aggregated per stay/admission.\n",
    "    if 'charttime' in df.columns:\n",
    "        df['charttime'] = pd.to_datetime(df['charttime'])\n",
    "        df['prediction_time'] = pd.to_datetime(df['prediction_time'])\n",
    "\n",
    "        # Filter to keep only measurements where charttime is before prediction_time\n",
    "        df_filtered = df[df['charttime'] < df['prediction_time']]\n",
    "        df_filtered = df_filtered[df_filtered['charttime'] >= (df_filtered['prediction_time'] - pd.Timedelta(hours=time))]\n",
    "\n",
    "        # Group by join key and keep the last measurement in the observation window\n",
    "        df_filtered = df_filtered.sort_values(by=[join_col, 'charttime'])\n",
    "        # last_df = df_filtered.groupby(join_col).tail(1)[[join_col] + columns_to_mean].reset_index(drop=True)\n",
    "        last_vals = (\n",
    "            df_filtered\n",
    "            .groupby(join_col, as_index=False)[columns_to_mean]\n",
    "            .agg(lambda s: s.dropna().iloc[-1] if s.notna().any() else np.nan)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # For pre-aggregated tables (e.g., first_day_vitalsign), keep one row per join key.\n",
    "        last_df = df.sort_values(by=[join_col]).drop_duplicates(join_col, keep='last')[[join_col] + columns_to_mean].reset_index(drop=True)\n",
    "\n",
    "    all_ids_df = pd.DataFrame({join_col: list(combined_ids)})\n",
    "    # final_df = pd.merge(all_ids_df, last_df, on=join_col, how='left')\n",
    "    final_df = pd.DataFrame({join_col: list(combined_ids)}).merge(last_vals, on=join_col, how='left')\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def calculate_nan_rate(df, columns):\n",
    "    nan_rates = {}\n",
    "    \n",
    "    # Calculate the NaN rate for each column\n",
    "    for column in columns:\n",
    "        nan_count = df[column].isna().sum()\n",
    "        nan_rate = nan_count / len(df) * 100  # Percentage of NaNs\n",
    "        nan_rates[column] = nan_rate\n",
    "    \n",
    "    return nan_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca9997",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "clot_df = run_query(build_query(\"mimiciv_derived.coagulation\", column_names=[\"*\"]), preview=False)\n",
    "columns_to_mean = ['inr','pt','fibrinogen']\n",
    "\n",
    "filtered_clot_df = extract_features(clot_df, valid_admissions, columns_to_mean, time=OBSERVATION_TIME)\n",
    "print(filtered_clot_df)\n",
    "nan_rates = calculate_nan_rate(filtered_clot_df, columns_to_mean)\n",
    "print(nan_rates)\n",
    "\n",
    "cardiac_df = run_query(build_query(\"mimiciv_derived.cardiac_marker\", column_names=[\"*\"]), preview=False)\n",
    "columns_to_mean = ['troponin_t']\n",
    "\n",
    "filtered_trop_df = extract_features(cardiac_df, valid_admissions, columns_to_mean, time=OBSERVATION_TIME)\n",
    "print(filtered_trop_df)\n",
    "nan_rates = calculate_nan_rate(filtered_trop_df, columns_to_mean)\n",
    "print(nan_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1572d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "abg_df = run_query(build_query(\"mimiciv_derived.bg\", column_names=[\"*\"]), preview=False)\n",
    "columns_to_mean = [\"po2\",\"pco2\",\"ph\",\"lactate\",\"so2\"]\n",
    "\n",
    "filtered_abg_df = extract_features(abg_df, valid_admissions, columns_to_mean, time=OBSERVATION_TIME)\n",
    "print(filtered_abg_df)\n",
    "nan_rates = calculate_nan_rate(filtered_abg_df, columns_to_mean)\n",
    "print(nan_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb698acc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bmp_df = run_query(build_query(\"mimiciv_derived.chemistry\", column_names=[\"hadm_id\", \"charttime\", \"bicarbonate\",\"bun\",\"creatinine\",\"glucose\"]), preview=False)\n",
    "bmp_features = [\"bicarbonate\",\"bun\",\"creatinine\",\"glucose\"]\n",
    "\n",
    "filtered_bmp_df = extract_features(bmp_df, valid_admissions, bmp_features, time=OBSERVATION_TIME)\n",
    "print(filtered_bmp_df)\n",
    "nan_rates = calculate_nan_rate(filtered_bmp_df, bmp_features)\n",
    "print(nan_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e740b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "wbc_df = run_query(build_query(\"mimiciv_derived.blood_differential\", column_names=[\"hadm_id\", \"charttime\", \"neutrophils_abs\", \"lymphocytes_abs\"]), preview=False)\n",
    "wbc_features = [\"neutrophils_abs\", \"lymphocytes_abs\"]\n",
    "\n",
    "filtered_wbc_df = extract_features(wbc_df, valid_admissions, wbc_features, time=OBSERVATION_TIME)\n",
    "print(filtered_wbc_df)\n",
    "nan_rates = calculate_nan_rate(filtered_wbc_df, wbc_features)\n",
    "print(nan_rates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867647bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Add other baseline information for patient (age and icu related information)\n",
    "demo_df = run_query(build_query(\"mimiciv_derived.age\", column_names=[\"*\"]), preview=False)\n",
    "\n",
    "# Suspected infection time per stay (for later filter: suspected infection before prediction_time)\n",
    "sepsis3_df = run_query(\n",
    "    build_query(\"mimiciv_derived.sepsis3\", column_names=[\"stay_id\", \"suspected_infection_time\"]),\n",
    "    preview=False\n",
    ")\n",
    "sepsis3_df[\"suspected_infection_time\"] = pd.to_datetime(sepsis3_df[\"suspected_infection_time\"])\n",
    "valid_admissions = valid_admissions.merge(\n",
    "    sepsis3_df.drop_duplicates(\"stay_id\"),\n",
    "    on=\"stay_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "filtered_demo_df = valid_admissions.merge(demo_df[[\"hadm_id\", \"age\"]], on=\"hadm_id\", how=\"left\")\n",
    "#print(filtered_demo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b343c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vitals_df = run_query(build_query(\"mimiciv_derived.vitalsign\", column_names=[\"stay_id\", \"charttime\", \"mbp\", \"heart_rate\", \"spo2\"]), preview=False)\n",
    "vitals_features = [\"mbp\", \"heart_rate\", \"spo2\"]\n",
    "\n",
    "filtered_vitals_df = extract_features(vitals_df, valid_admissions, vitals_features, time=OBSERVATION_TIME, join_col='stay_id')\n",
    "nan_rates = calculate_nan_rate(filtered_vitals_df, vitals_features)\n",
    "print(nan_rates)\n",
    "\n",
    "stay_map = valid_admissions[['hadm_id', 'stay_id']].drop_duplicates('stay_id')\n",
    "\n",
    "filtered_vitals_df = (\n",
    "    stay_map\n",
    "    .merge(filtered_vitals_df, on='stay_id', how='left')\n",
    "    .drop(columns=['stay_id'])\n",
    ")\n",
    "\n",
    "print(filtered_vitals_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28732892",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_df = filtered_bmp_df.merge(filtered_abg_df, on='hadm_id', how='left')\n",
    "data_df = data_df.merge(filtered_clot_df, on='hadm_id', how='left')\n",
    "data_df = data_df.merge(filtered_trop_df, on='hadm_id', how='left')\n",
    "data_df = data_df.merge(filtered_vitals_df, on='hadm_id', how='left')\n",
    "data_df = data_df.merge(filtered_wbc_df, on='hadm_id', how='left')\n",
    "data_df = data_df.merge(\n",
    "    filtered_demo_df[['hadm_id', 'boolean_value', 'age', 'gender', 'icu_type', 'operation_type', 'ventilation_status', 'suspected_infection_time', 'prediction_time']],\n",
    "    on='hadm_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "need_columns = bmp_features + vitals_features\n",
    "# Only keep rows that have at least one non-missing value among the lab features\n",
    "data_df = data_df.dropna(subset=need_columns, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d846e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "llm_feature_mapping = {\n",
    "    # --- Demographics & Target ---\n",
    "    'age': 'Age',\n",
    "    'gender': 'Gender',\n",
    "    'icu_type': 'ICU Type',\n",
    "    'operation_type': 'Operation Type',\n",
    "    'ventilation_status': 'Ventilation Status',\n",
    "    \n",
    "    # --- Routine Vitals (Automatic / Low Discretion) ---\n",
    "    'heart_rate': 'Heart Rate (BPM)',\n",
    "    'map': 'Mean Arterial Pressure (MAP)',\n",
    "    'spo2': 'Pulse Oximetry (SpO2)',\n",
    "    \n",
    "    # --- Metabolic Panel (Routine Venous Draw) ---\n",
    "    'bicarbonate': 'Serum Bicarbonate (HCO3)',\n",
    "    'bun': 'Blood Urea Nitrogen (BUN)',\n",
    "    'creatinine': 'Serum Creatinine',\n",
    "    'glucose': 'Serum Glucose',\n",
    "    \n",
    "    # --- Critical Labs (High Discretion / \"The Signal\") ---\n",
    "    # \"Serum\" implies a specific order was placed\n",
    "    'lactate': 'Serum Lactate', \n",
    "    'inr': 'INR (Coagulation)',\n",
    "    'pt': 'Prothrombin Time (PT)',\n",
    "    'fibrinogen': 'Fibrinogen',\n",
    "    'troponin_t': 'Troponin T',\n",
    "    'neutrophils_abs': 'Neutrophils Absolute Count',\n",
    "    'lymphocytes_abs': 'Lymphocytes Absolute Count',\n",
    "    \n",
    "    # --- Arterial Blood Gas (Painful / High Discretion) ---\n",
    "    # Renaming these is CRITICAL so the LLM knows they are from an Art Line/Stab\n",
    "    # and not just a finger probe.\n",
    "    'ph': 'Arterial pH',\n",
    "    'po2': 'Arterial O2 Pressure (PaO2)',\n",
    "    'pco2': 'Arterial CO2 Pressure (PaCO2)',\n",
    "    'so2': 'Arterial O2 Saturation (SaO2)',\n",
    "}\n",
    "\n",
    "# Apply the renaming\n",
    "# Assuming your dataframe is named 'data_df'\n",
    "data_df.rename(columns=llm_feature_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2d2c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Filter data_df to only MICU patients\n",
    "micu_df = data_df[data_df['ICU Type'] == 'Medical Intensive Care Unit (MICU)']\n",
    "\n",
    "# Compute prevalence of boolean_value for micu_df\n",
    "if 'boolean_value' in micu_df.columns:\n",
    "    prevalence = micu_df['boolean_value'].mean()\n",
    "    print(f\"Prevalence of boolean_value in MICU cohort: {prevalence:.3f}\")\n",
    "else:\n",
    "    print(\"Column 'boolean_value' not found in micu_df.\")\n",
    "\n",
    "ccu_df = data_df[data_df['ICU Type'] == 'Coronary Care Unit (CCU)']\n",
    "\n",
    "# Compute prevalence of boolean_value for ccu_df\n",
    "if 'boolean_value' in ccu_df.columns:\n",
    "    prevalence = ccu_df['boolean_value'].mean()\n",
    "    print(f\"Prevalence of boolean_value in CCU cohort: {prevalence:.3f}\")\n",
    "else:\n",
    "    print(\"Column 'boolean_value' not found in ccu_df.\")\n",
    "\n",
    "# Remove 'operation type' column if present before saving\n",
    "micu_save = micu_df.drop(columns=['operation type'], errors='ignore')\n",
    "ccu_save = ccu_df.drop(columns=['operation type'], errors='ignore')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
